[tool:pytest]
# Test discovery patterns
testpaths = tests
python_files = test_*.py *_test.py
python_classes = Test* *Test
python_functions = test_* *_test

# Core pytest settings
asyncio_mode = auto
asyncio_default_fixture_loop_scope = function
cache_dir = .pytest_cache
maxfail = 10
timeout = 300

# Test execution options
addopts = 
    # Verbosity and output
    -v
    --tb=short
    --strict-markers
    --strict-config
    --disable-warnings
    
    # Coverage reporting
    --cov=backend.app
    --cov-branch
    --cov-report=term-missing:skip-covered
    --cov-report=html:artifacts/htmlcov
    --cov-report=xml:artifacts/coverage.xml
    --cov-report=json:artifacts/coverage.json
    --cov-fail-under=80
    
    # Test result reporting
    --junitxml=artifacts/test-results/junit.xml
    --html=artifacts/test-results/report.html
    --self-contained-html
    
    # Performance and timing
    --durations=10
    --durations-min=1.0
    
    # Parallel execution support
    --numprocesses=auto
    --maxprocesses=4
    
    # Additional reporting
    --json-report
    --json-report-file=artifacts/test-results/report.json

# Test markers for categorization
markers =
    # Test type markers
    unit: Unit tests - fast, isolated tests
    integration: Integration tests - test component interactions
    e2e: End-to-end tests - full system testing
    api: API endpoint tests
    service: Service layer tests
    model: Model/validation tests
    
    # Performance and timing markers
    slow: Slow running tests (>5 seconds)
    fast: Fast running tests (<1 second)
    performance: Performance benchmark tests
    load: Load testing scenarios
    
    # Environment markers
    local: Tests that run only in local environment
    ci: Tests for CI/CD environments
    docker: Tests requiring Docker
    network: Tests requiring network access
    
    # Test state markers
    stable: Stable tests that should always pass
    flaky: Tests known to be flaky
    skip_ci: Skip in CI environment
    
    # Feature markers
    pdf: PDF processing related tests
    upload: File upload functionality tests
    search: Search functionality tests
    viewer: PDF viewer component tests
    auth: Authentication related tests
    
    # Priority markers
    critical: Critical functionality tests
    regression: Regression test cases
    smoke: Smoke test suite
    
    # Database markers
    db: Tests requiring database
    no_db: Tests that should not use database
    
    # Mock markers
    mock: Tests using mocks
    real: Tests using real services

# Filter warnings
filterwarnings =
    ignore::DeprecationWarning:pkg_resources.*
    ignore::pytest.PytestUnraisableExceptionWarning
    ignore::RuntimeWarning:asyncio.*
    ignore::PendingDeprecationWarning
    ignore::FutureWarning:pydantic.*
    error::UserWarning
    
# Logging configuration
log_cli = true
log_cli_level = INFO
log_cli_format = [%(asctime)s] [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = artifacts/test-logs/pytest.log
log_file_level = DEBUG
log_file_format = [%(asctime)s] [%(levelname)8s] %(name)s (%(filename)s:%(lineno)d): %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Performance optimizations
collect_ignore = [
    "setup.py",
    "docs",
    "build",
    "dist",
    ".eggs"

# Minimum version requirements
minversion = 7.0
required_plugins = 
    pytest-cov>=4.1.0
    pytest-html>=3.1.0
    pytest-json-report>=1.5.0
    pytest-xdist>=3.0.0
    pytest-asyncio>=0.21.0
    pytest-benchmark>=4.0.0
    pytest-mock>=3.10.0